{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQv6Uy2/dBfuqfENMFkbYn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arohanajit/Basket-Analysis/blob/master/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27N9FE5-DX1L"
      },
      "source": [
        "#Install necessary libraries\n",
        "!pip install pytorch-model-summary\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import datasets, transforms, models\n",
        "from pytorch_model_summary import summary\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.notebook import tqdm\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-bVl8n5DW0m"
      },
      "source": [
        "\n",
        "%%capture\n",
        "#Use loader to import data from kaggle\n",
        "if 'loader.py' not in os.listdir():\n",
        "    !wget https://raw.githubusercontent.com/arohanajit/disease-detector/master/loader.py\n",
        "import loader\n",
        "if 'data' not in os.listdir():\n",
        "    loader.load_data()\n",
        "    !kaggle datasets download -d arohanajit232/gurmukhidataset\n",
        "    !unzip gurmukhidataset.zip\n",
        "    !rm gurmukhidataset.zip\n",
        "    shutil.rmtree('data/Python code')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_GTDjcQFQ_r"
      },
      "source": [
        "# Basic resizing, normalization and type conversion of data to tensor for processing\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es9DMpqBT4YE"
      },
      "source": [
        "# Division into test and train\n",
        "data_dir = 'data/'\n",
        "data = datasets.ImageFolder(data_dir,transform=data_transforms)\n",
        "test_size = 0.2\n",
        "print(len(data))\n",
        "class_labels = list(data.class_to_idx.keys())\n",
        "print(class_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5jbEO8HT9Ht"
      },
      "source": [
        "# Random sample and batch distribution for Batch GD and bias removal\n",
        "num_train = len(data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "test_split = int(np.floor((test_size) * num_train))\n",
        "test_idx, train_idx = indices[:test_split], indices[test_split:]\n",
        "\n",
        "print(len(test_idx), len(train_idx))\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train' : len(train_idx),\n",
        "    'test' : len(test_idx)\n",
        "}\n",
        "\n",
        "loaders = {\n",
        "    'train': torch.utils.data.DataLoader(data, batch_size=64, sampler=train_sampler),\n",
        "    'test': torch.utils.data.DataLoader(data, batch_size=32, sampler=test_sampler),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-N9F36aUAGf"
      },
      "source": [
        "#Display some images with labels\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  \n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "\n",
        "dataiter = iter(loaders['train'])\n",
        "images, labels = dataiter.next()\n",
        "print(images.shape,labels.shape)\n",
        "images = images.numpy() \n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(5, 4, idx+1, xticks=[], yticks=[])\n",
        "    imshow(images[idx])\n",
        "    ax.set_title(class_labels[int(labels[idx])],fontsize=15,color='white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEmvwVskUBup"
      },
      "source": [
        "#Graphing train and test loss\n",
        "def graph_loss(train_loss,test_loss):\n",
        "    fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
        "    ax.plot(train_loss)\n",
        "    ax.plot(test_loss)\n",
        "    ax.legend(['Train Loss','Test Loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07F-euzaUDR_"
      },
      "source": [
        "#Function to train model\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    train_loss,test_loss = [],[]\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in loaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            \n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "            else:\n",
        "                test_loss.append(epoch_loss)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    graph_loss(train_loss, test_loss)\n",
        "    \n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBOfAXLQUETN"
      },
      "source": [
        "# Function to visualise model results\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loaders['test']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            fig = plt.figure(figsize=(25, 16))\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = fig.add_subplot(2, num_images//2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {} actual: {}'.format(class_labels[preds[j]], class_labels[labels.cpu().data[j]]),fontsize=15,color='white')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFD9eHu-UF_j"
      },
      "source": [
        "#Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqp191yVVbVQ"
      },
      "source": [
        "# Define pretrained transfer learning model\n",
        "model_ft = models.densenet201(pretrained=True)\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSxcEAarVOfC"
      },
      "source": [
        "# Selection model paramters\n",
        "#Freezing model layers\n",
        "for params in model_ft.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "#Defining classifiers\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Linear(num_ftrs, len(class_labels))\n",
        "\n",
        "# Unfreezing bottom layers\n",
        "for name,params in zip(model_ft.features.denseblock4,model_ft.features.denseblock4.parameters()):\n",
        "    if int(name[10:]) >= 26:\n",
        "        params.requires_grad = True\n",
        "\n",
        "#Summary of model and transfer to GPU\n",
        "print(summary(model_ft, torch.zeros((1, 3, 256, 256))))\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#Optimisation\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boVs5zjrUTDw"
      },
      "source": [
        "#Training\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZT1TweWUa7V"
      },
      "source": [
        "#Visualization\n",
        "visualize_model(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI6oNqSiUc-J"
      },
      "source": [
        "#Save model\n",
        "torch.save(model_ft,'model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzGyid7w_pv2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}